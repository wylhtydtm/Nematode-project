{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18_unfreeze_last_fully_connected_layer_only.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqOdmNoZaUh+M4zA9ILjq3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wylhtydtm/Nematode-project/blob/master/Resnet18_unfreeze_last_fully_connected_layer_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgZxRnJvQ0rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import tables\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywkrzxzzQ2Sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLosses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8jD6fVHRBTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shift_and_normalize(data):  #Preprocessing step \n",
        "    data_m = data.view(np.ma.MaskedArray)\n",
        "    data_m.mask = data==0\n",
        "    if data.ndim == 3:\n",
        "        sub_d = np.percentile(data, 95, axis=(1,2)) #let's use the 95th as the value of the background\n",
        "        data_m -= sub_d[:, None, None]\n",
        "    else:\n",
        "        sub_d = np.percentile(data, 95)\n",
        "        data_m -= sub_d\n",
        "        \n",
        "    data /= 255\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdNDyQ9zTaXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_rescale(img, for_pillow=False):\n",
        "    \"\"\"\n",
        "    Rescale the image between 0 and 1, make it 3D if it was just 2D.\n",
        "    Unlike prep_for_pytorch, no need to make it 4d (batches) because\n",
        "    the images will be loaded through the dataloader, and that will already\n",
        "    create the 4d batches.\n",
        "    In tierpsy, I manually make a N_images x channels x width x height batches,\n",
        "    and the input to prep_for_pytorch is n_images x w x h (because grayscale)\n",
        "    While here the ndim==3 refers to channels...\n",
        "    If you don't use the dataloader, you'll still need to add one dimension\n",
        "    in the appropriate place\"\"\"\n",
        "    assert img.ndim==2, 'img_rescale only works with 2d array for now'\n",
        "    img = img - img.min()\n",
        "    img = img / img.max()\n",
        "    if for_pillow:\n",
        "        img *= 255\n",
        "        img = img.astype(np.uint8)\n",
        "    else:\n",
        "        img = img.astype(np.float32)[None, :, :] # c,w,h\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5xP9sngIRsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class new_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, hdf5_filename, which_set='train', transform=None):\n",
        "\n",
        "        self.fname = hdf5_filename\n",
        "        self.set_name = which_set\n",
        "        # get labels info\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "            tmp = pd.DataFrame.from_records(\n",
        "                fid.get_node('/'+self.set_name)['sample_data'].read())\n",
        "        self.label_info = tmp[['img_row_id', 'is_worm', 'is_avelinos']]\n",
        "        # size in hdf5 file is 160x160 (in theory), but we train on 80x80\n",
        "        self.roi_size = 80  # size we want to train on\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "            dataset_size = fid.get_node('/train/mask').shape[1]\n",
        "        pad = (dataset_size - self.roi_size)/2\n",
        "        self.dd = [pad, dataset_size-pad]\n",
        "        # any transform?\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_info)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "\n",
        "        # I could just use index because img_row_id is the same as the index of\n",
        "        # label_info, but just in case we ever want to shuffle...\n",
        "        label_info = self.label_info.iloc[index]\n",
        "        img_row_id = label_info['img_row_id']\n",
        "        # read images from disk\n",
        "        # I could just use index because img_row_id is the same as the index of\n",
        "        # label_info, but just in case we ever want to shuffle...\n",
        "        label_info = self.label_info.iloc[index]\n",
        "        img_row_id = label_info['img_row_id']\n",
        "        # read images from disk\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "          roi_data = fid.get_node(\n",
        "                '/' + self.set_name + '/mask')[img_row_id,\n",
        "                                               self.dd[0]:self.dd[1],\n",
        "                                               self.dd[0]:self.dd[1]].copy()\n",
        "\n",
        "        # shift_and_normalize wants a float, and pytorch a single, use single\n",
        "        img = roi_data.astype(np.float32)\n",
        "        img = shift_and_normalize(img)\n",
        "\n",
        "        # as of now, the model works even without PIL\n",
        "        # but transform only works with pil, so:\n",
        "        if self.transform:  # if any transforms were given to initialiser\n",
        "            img = img_rescale(img, for_pillow=True)\n",
        "            img = Image.fromarray(img)\n",
        "            img = img.convert(mode='RGB')\n",
        "            img = self.transform(img)\n",
        "      \n",
        "        else:\n",
        "            img = img_rescale(img, for_pillow=False)\n",
        "\n",
        "        # read labels too\n",
        "        labels = label_info['is_worm']\n",
        "        labels = np.array(labels, dtype=np.float32).reshape(-1, 1)\n",
        "        labels = torch.from_numpy(labels)\n",
        "\n",
        "        return img, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1kypSGtKTNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hd = Path('/content/drive/My Drive')\n",
        "fname = hd / 'Hydra_Phenix_dataset.hdf5'\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 128\n",
        "\n",
        "    # define transforms\n",
        "    # do we need vertical/hor flip?\n",
        "training_transform = transforms.Compose([transforms.RandomVerticalFlip(p=0.4),\n",
        "                                         transforms.RandomHorizontalFlip(p=0.4),\n",
        "                                         transforms.ColorJitter(contrast=0.2, hue=0.2),\n",
        "                                         transforms.ToTensor()])\n",
        "validation_transform = transforms.Compose([transforms.RandomVerticalFlip(p=0.4),\n",
        "                                           transforms.RandomHorizontalFlip(p=0.4),\n",
        "                                           transforms.ColorJitter(contrast=0.2, hue=0.2),\n",
        "                                           transforms.ToTensor()])\n",
        "    \n",
        "test_transform = transforms.ToTensor()\n",
        "\n",
        "\n",
        "# create datasets\n",
        "train_data = new_dataset(fname, which_set='train',transform=training_transform)\n",
        "val_data = new_dataset(fname, which_set='val',transform=validation_transform)\n",
        "\n",
        "# create dataloaders\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=4)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, num_workers=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsQ_unUPO2ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = new_dataset(fname, which_set='test',transform=test_transform)\n",
        "\n",
        "test_loader=DataLoader(test_data, shuffle=True, batch_size=batch_size, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sss1T0AnNSB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"validation\": val_loader\n",
        "}\n",
        "dataset_sizes = {'train':len(train_loader.dataset), 'validation':len(val_loader.dataset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZK9XD7ROx7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85759137-abcf-4764-d5a7-538fde5298ce"
      },
      "source": [
        "# Checking whether the input image has the right channel\n",
        "img = train_data[0][0]\n",
        "img =img.unsqueeze(0)\n",
        "print(img.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 80, 80])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRO4KNqeO0MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = {0: 'non_worm', 1: 'worm'}\n",
        "\n",
        "images, labels = next(iter(train_loader)) \n",
        "out = torchvision.utils.make_grid(images,nrow=5)\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor. transpose; to get height and width from tensor. \n",
        "    In Pytorch, images are presented as [channels, height, width]\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))  \n",
        "    plt.imshow(inp)\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0.02, hspace=0)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  \n",
        "\n",
        "imshow(out, title=( 'Labels', [classes[x.item()] for x in labels]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9HgsX0MlpKbu",
        "colab": {}
      },
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False  # freeze all network except the final layer in model_conv ResNeT18 for training\n",
        "        \n",
        "num_ftrs = model_conv.fc.in_features # to discover parameters of newly constructed modules \n",
        "model_conv.fc = nn.Sequential(nn.Linear(num_ftrs, 256), nn.Linear(256,2))  #the final layer in our model, 2 classes only\n",
        "    \n",
        "model_conv = model_conv.to(device)    \n",
        "learning_rate = 0.001\n",
        "num_epoch = 50  # gradient descent that controls no of complete passes through the training dataset\n",
        "    \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimiser_conv = torch.optim.Adam(model_conv.parameters(),lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_U3ii-N0plki",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimiser, num_epoch):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    Liveloss= PlotLosses()   \n",
        "    #Iterate through epochs\n",
        "    for epoch in range(num_epoch):\n",
        "        logs = {}\n",
        "        print('Epoch{}/{}'.format(epoch, num_epoch -1))\n",
        "        print('-' * 15)\n",
        "  \n",
        "        #Each epoch has a training and validation phase        \n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "              \n",
        "            else:\n",
        "                model.eval()\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "        \n",
        "            for ii, (inputs, labels) in enumerate (dataloaders[phase]):\n",
        "                inputs,labels = inputs.to(device), labels.to(device)\n",
        "                labels = labels.view(-1)\n",
        "                labels = labels.long()\n",
        "                optimiser.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, pred = torch.max(outputs, dim= 1)      \n",
        "                    loss = criterion(outputs, labels)\n",
        "                                   \n",
        "                  #backward and optimze only in the training pahse\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()  #Loss and backpropagation\n",
        "                        optimiser.step()\n",
        "\n",
        "                _, pred = torch.max(outputs, dim= 1)              \n",
        "                running_loss += loss.detach()  * inputs.size(0) \n",
        "                running_corrects += torch.sum(pred == labels.data)\n",
        "\n",
        "\n",
        "             # calculate average losses fo the entire epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            prefix = ''\n",
        "            if phase == 'validation':\n",
        "                prefix = 'val_'\n",
        "                \n",
        "            logs[prefix + ' loss'] = epoch_loss\n",
        "            logs[prefix + 'accuracy'] = epoch_acc\n",
        "                                               \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "                 \n",
        "            #Ddeep copy the model\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        Liveloss.update(logs)\n",
        "        Liveloss.send()\n",
        "\n",
        "        print()\n",
        "        \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s. Saving model...'.format(time_elapsed //60, time_elapsed % 60))\n",
        "    print('Best Val Acc: {.4f}'.format(best_acc)) \n",
        "    model.load_state_dic(best_model_wts)\n",
        "    return model  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pteG6dzspXMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv=train_model(model_conv, criterion, optimiser_conv, num_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbUAkNP5EOka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH= '/content/drive/My Drive/Resnet18_model_adam_epoch100.pth'\n",
        "torch.save(model_conv.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Wf9EXeERiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cpu')\n",
        "model_conv = model_conv.to(device)   \n",
        "model_conv.load_state_dict(torch.load('drive/My Drive/Resnet18_model_adam_epoch100.pth',map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T3PJyoLETCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgMZny1EEUcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "if torch.cuda.is_available():\n",
        "    model_conv.cuda()\n",
        "\n",
        "summary(model_conv,(3, 80, 80))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbYf7sju99YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def measure_performance(predictions, labels):\n",
        "    \"\"\"\n",
        "    I think there's scikit learn functions for this\n",
        "    but found out after writing the function\n",
        "    \"\"\"\n",
        "    # go logical for ease\n",
        "    predictions = predictions.astype(bool)\n",
        "    labels = labels.astype(bool)\n",
        "    # true positives\n",
        "    tp = np.logical_and(predictions, labels).sum()\n",
        "    # true negatives\n",
        "    tn = np.logical_and(~predictions, ~labels).sum()\n",
        "    # false positives\n",
        "    fp = np.logical_and(predictions, ~labels).sum()\n",
        "    # false negatives\n",
        "    fn = np.logical_and(~predictions, labels).sum()\n",
        "    # accuracy\n",
        "    accuracy = (tp + tn) / len(predictions)\n",
        "    print(f\"accuracy = {accuracy}\")\n",
        "    # precision\n",
        "    precision = tp / (tp + fp)\n",
        "    print(f\"precision = {precision}\")\n",
        "    # recall\n",
        "    recall = tp / (tp + fn)\n",
        "    print(f\"recall = {recall}\")\n",
        "    # F1\n",
        "    f1 = 2*tp / (2*tp + fp + fn)\n",
        "    print(f\"F1 score = {f1}\")\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ChVJJqEWQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = []\n",
        "predictions = []\n",
        "# Do not perform backpagtion during inference, to reduce memory usage\n",
        "with torch.no_grad():\n",
        "  for images, labs in test_loader:\n",
        "    images = images.to(device)\n",
        "    preds = model_conv(images)\n",
        "    preds = torch.argmax(preds, axis=1)\n",
        "    predictions.append(preds)\n",
        "    labels.append(labs)\n",
        "\n",
        "  predictions = np.concatenate(predictions, axis=0)\n",
        "  labels = np.concatenate(labels, axis=0).squeeze()\n",
        "\n",
        "print(\"\\nPerformance \")\n",
        "measure_performance(predictions, labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}