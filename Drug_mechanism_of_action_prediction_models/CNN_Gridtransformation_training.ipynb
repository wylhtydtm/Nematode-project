{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Gridtransformation_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1opT-mAmrQrnO2Pvi6CH9S-Ct5YuvNwfi",
      "authorship_tag": "ABX9TyPa4jMnTj4D/qWQG9VD6ZDi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wylhtydtm/Nematode-project/blob/master/CNN_Gridtransformation_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGPQHX9vOsBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import tables\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn import preprocessing\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFXZx2mFVnHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class timeseries_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, hdf5_filename, which_set='train', transform=None):\n",
        "\n",
        "        self.fname = hdf5_filename\n",
        "        self.set_name = which_set\n",
        "        # get labels info\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "            tmp = pd.DataFrame.from_records(\n",
        "                fid.get_node('/'+self.set_name)['labels'].read())\n",
        "        self.label_info = tmp[['imaging_plate_drug_concentration', 'MOA_group', 'ts_id']]\n",
        "        # any transform?\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_info)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "\n",
        "        label_info = self.label_info.iloc[index]\n",
        "        ts_id = label_info['ts_id'].astype(int)\n",
        "        # read data from disk\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "          timeseries_data = fid.get_node(\n",
        "                '/' + self.set_name + '/tw_data')[ts_id,:,:].copy()\n",
        "\n",
        "        if self.transform:  # if any transforms were given to initialiser\n",
        "            timeseries_data *= 255\n",
        "            ts = timeseries_data.astype(np.uint8)       \n",
        "            ts = Image.fromarray(ts)\n",
        "            ts = self.transform(ts)\n",
        "        else:\n",
        "            ts = img_rescale(timeseries_data, for_pillow=False)\n",
        "        # read labels too\n",
        "        labels = label_info['MOA_group']\n",
        "        labels = np.array(labels, dtype=np.float32).reshape(-1, 1)\n",
        "        labels = torch.from_numpy(labels)\n",
        "        \n",
        "        return ts, labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbIEYA3rV5ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " hd = Path('/content/drive/My Drive')\n",
        " fname = hd / 'speed_grid_encoded_80and200dimensions.hdf'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQEGHAjGWCZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-HYA6KwWJV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tw_transform=  transforms.Compose([transforms.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upBNu6kzWLTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = timeseries_dataset(fname, which_set='train',transform=tw_transform)\n",
        "val_data = timeseries_dataset(fname, which_set='val',transform=tw_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P616pEZsW1I7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=4)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-zGcK0sW2X0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5989aa4-1bfc-40a8-91d4-152867070bc7"
      },
      "source": [
        "print(train_data[1][0].shape)\n",
        "print(train_data[1][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 80, 200])\n",
            "torch.Size([1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du4jZikrW5Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = next(iter(train_loader)) \n",
        "out = torchvision.utils.make_grid(images,nrow=5)\n",
        "imshow(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWU3J8mOXgxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor. transpose; to get height and width from tensor. \n",
        "    In Pytorch, images are presented as [channels, height, width]\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))  \n",
        "    plt.imshow(inp,interpolation='nearest', cmap='gray', aspect='auto')\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0.02, hspace=0)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecUInqWin02x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4d4b27a9-570d-448b-d832-f27f8a8243e3"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2, 1, 1)\n",
        "ax2 = fig.add_subplot(2, 1, 2)\n",
        "ax1.imshow(train_data[1][0].squeeze(0), interpolation='nearest', cmap='gray', aspect='auto')\n",
        "ax2.imshow(train_data[0][0].squeeze(0), interpolation='nearest', cmap='gray', aspect='auto')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPZZHAGu0B5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0466b5d-458a-442a-9732-fd2937bfbf4d"
      },
      "source": [
        "ts_1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 876])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoRTtz6esftR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "                nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                nn.Dropout2d(0.25),\n",
        "                nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.LeakyReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                nn.Dropout2d(0.25), # activation layer\n",
        "                nn.Conv2d(64, 64, kernel_size=5, stride=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2)) # activation layer\n",
        "        \n",
        "        self.drop_out = nn.Dropout2d(0.3)\n",
        "        self.fc_layers =nn.Sequential(nn.Linear(9856, 7))# define fully connected layer\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x) # pass input through conv layers\n",
        "        x = self.drop_out(x)  \n",
        "        x = x.view(x.shape[0], -1) # flatten output for fully connected layer, batchize,-1 do whatever it needs to be \n",
        "        x = self.fc_layers(x)# pass  through fully connected layer\n",
        "        x = F.softmax(x, dim=1) #softmax activation function on outputs, get probability disatribution on output, all ouputs add to 1\n",
        "        return x \n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "\n",
        "cnn = ConvNet().to(device) # to instantiate model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(cnn.parameters(), lr= learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyHFeZXKbY2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLosses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N63DbhxobrW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"validation\": val_loader\n",
        "}\n",
        "dataset_sizes = {'train':len(train_loader.dataset), 'validation':len(val_loader.dataset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prkcy7MwbvEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimiser, epochs, verbose= True, tag ='Loss/Train'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    Liveloss= PlotLosses()\n",
        "    #Iterate through epochs\n",
        "    for epoch in range(epochs):\n",
        "        logs = {}\n",
        "        print('Epoch{}/{}'.format(epoch, epochs-1))\n",
        "        print('-' * 15)\n",
        "  \n",
        "        #Each epoch has a training and validation phase        \n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "              \n",
        "            else:\n",
        "                model.eval()\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            for index, (inputs, labels) in enumerate (dataloaders[phase]):\n",
        "                inputs,labels = inputs.to(device), labels.to(device)\n",
        "                labels = labels.view(-1) # flatten\n",
        "                labels = labels.long()\n",
        "                prediction = model(inputs) \n",
        "                prediction = prediction.view(labels.size(0), -1)  #flatten\n",
        "                loss = criterion(prediction, labels) #calculate the loss between predicted and ground truth\n",
        "                optimiser.zero_grad() # zero the paratmeter gradients\n",
        "                  \n",
        "                if phase == 'train':\n",
        "                    if verbose: print('Epoch:', epoch, '\\tBatch:', index, '\\tLoss', loss.item())\n",
        "                    loss.backward()  \n",
        "                    optimiser.step() # backward + optimize only if in training phase\n",
        "\n",
        "                _, pred = torch.max(prediction, dim= 1)                  \n",
        "                running_loss += loss.detach() * inputs.size(0) \n",
        "                running_corrects += torch.sum(pred == labels.data)\n",
        "\n",
        "             # calculate average losses fo the entire epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            prefix = ''\n",
        "            if phase == 'validation':\n",
        "                prefix = 'val_'\n",
        "                \n",
        "            logs[prefix + ' loss'] = epoch_loss\n",
        "            logs[prefix + 'accuracy'] = epoch_acc\n",
        "                                    \n",
        "            #Deep copy the model\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "              best_acc = epoch_acc\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        Liveloss.update(logs)\n",
        "        Liveloss.send()\n",
        "\n",
        "    time_elapse = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapse // 60, time_elapse % 60))\n",
        "    print('Best Val Acc: {}'.format(best_acc)) \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZdQMc3TbxER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = train_model(cnn, criterion, optimiser, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}