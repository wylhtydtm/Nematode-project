{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_8signals.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XPJv2X2Y7F9jvc17mls53U909HIdXm_q",
      "authorship_tag": "ABX9TyN11Na7hINBWhlT8noeHTjG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wylhtydtm/Nematode-project/blob/master/CNN_8signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyTO1IbLBAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import tables\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn import preprocessing\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGUwhWU9pGU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLosses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Zbh4SL2s5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class timeseries_dataset(Dataset):\n",
        "\n",
        "    def __init__(self, hdf5_filename, which_set='train', transform=None):\n",
        "\n",
        "        self.fname = hdf5_filename\n",
        "        self.set_name = which_set\n",
        "        # get labels info\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "            tmp = pd.DataFrame.from_records(\n",
        "                fid.get_node('/'+self.set_name)['labels'].read())\n",
        "        self.label_info = tmp[['imaging_plate_drug_concentration', 'MOA_group', 'ts_id']]\n",
        "        # any transform?\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_info)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        # I could just use index because ts_id is the same as the index of label_info, but just in case of shuffling...\n",
        "        label_info = self.label_info.iloc[index]\n",
        "        ts_id = label_info['ts_id'].astype(int)\n",
        "        # read data from disk\n",
        "        with tables.File(self.fname, 'r') as fid:\n",
        "          timeseries_data = fid.get_node(\n",
        "                '/' + self.set_name + '/tw_data')[ts_id,:,:].copy()\n",
        "          \n",
        "        ts = timeseries_data.astype(np.float32)\n",
        "        ts = ts.T\n",
        "\n",
        "        if self.transform:  # if any transforms were given to initialiser\n",
        "\n",
        "            #ts = ts.reshape((8,876),order='A') \n",
        "            ts *= 255\n",
        "            ts = ts.astype(np.uint8)         \n",
        "            ts = self.transform(ts)\n",
        "            ts = ts.squeeze(0)\n",
        "          \n",
        "        # read labels too\n",
        "        labels = label_info['MOA_group']\n",
        "        labels = np.array(labels, dtype=np.float32).reshape(-1, 1)\n",
        "        #lb = preprocessing.LabelBinarizer()\n",
        "         #labels = lb.fit_transform(labels)\n",
        "        labels = torch.from_numpy(labels)\n",
        "\n",
        "        #read the drug concentration\n",
        "        #concentration = label_info['imaging_plate_drug_concentration']\n",
        "        #concentration = np.array(concentration, dtype=np.float32).reshape(-1, 1)\n",
        "        #concentration = torch.from_numpy(concentration)\n",
        "\n",
        "        return timeseries_data, labels #, concentration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KRkiRH-keFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor. transpose; to get height and width from tensor. \n",
        "    In Pytorch, images are presented as [channels, height, width]\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))  \n",
        "    plt.imshow(inp)\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0.02, hspace=0)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkeV-pT8ospR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " hd = Path('/content/drive/My Drive')\n",
        " fname = hd / 'Timeseries_0708_8signals_normalizd.hdf'\n",
        " fname_2 = hd/'Timeseries_0708_8signals_normalizd.hdf'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnobAZnIpUH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oAiMjHrpa81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tw_transform= transforms.ToTensor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M9yhcqIqIkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = timeseries_dataset(fname, which_set='train',transform=tw_transform)\n",
        "val_data = timeseries_dataset(fname, which_set='val',transform=tw_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggLTDqJiqdQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=4)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, num_workers=4)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A--vXS6xSn-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_1 = train_data[0][0]\n",
        "print(ts_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qURoxWrFzYVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i1,id= next(iter(train_loader))\n",
        "print(i1.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDv6Hb2GSipR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualizing images\n",
        "i = 0\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(221), plt.plot(train_data[i][0]), plt.title(train_data[i][1])\n",
        "plt.subplot(222), plt.plot(train_data[i+25][0]), plt.title(train_data[i+25][1])\n",
        "plt.subplot(223), plt.plot(train_data[i+50][0]), plt.title(train_data[i+50][1])\n",
        "plt.subplot(224), plt.plot(train_data[i+75][0]), plt.title(train_data[i+75][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8heQdZbE4h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels= next(iter(train_loader)) \n",
        "out = torchvision.utils.make_grid(images,nrow=5)\n",
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y7PVHkdtVaKU",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(40,60))\n",
        "plt.imshow(images[0].squeeze(0).numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e7ZTPZ1ViJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_2=val_data[0][0]\n",
        "plt.figure(figsize=(40,60))\n",
        "plt.imshow(ts_2.squeeze(0).numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OupqbeL_7KkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(val_data[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0uLnoUV5eC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "                nn.Conv1d(8, 40, kernel_size=5, stride=1, padding=1),\n",
        "                nn.BatchNorm1d(40),\n",
        "                nn.ReLU(), # activation layer\n",
        "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "                nn.Conv1d(40, 80, kernel_size=5, stride=1, padding=1),)\n",
        "        self.drop_out = nn.Dropout(0.5)\n",
        "        self.fc_layers = nn.Sequential(nn.Linear(33200,12))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.drop_out(x)# pass input through conv layers\n",
        "        x = x.view(x.shape[0], -1) # flatten output for fully connected layer, batchize,-1 do whatever it needs to be \n",
        "        x = self.fc_layers(x)# pass  through fully connected layer #\n",
        "        return x \n",
        "\n",
        "learning_rate = 0.0001\n",
        "epochs = 100\n",
        "\n",
        "cnn = ConvNet().to(device) # to instantiate model\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(cnn.parameters(), lr= learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ViJy5Fomcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"validation\": val_loader\n",
        "}\n",
        "dataset_sizes = {'train':len(train_loader.dataset), 'validation':len(val_loader.dataset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBKCYN8Io3e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimiser, epochs, verbose= True, tag ='Loss/Train'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    Liveloss= PlotLosses()\n",
        "    #Iterate through epochs\n",
        "    for epoch in range(epochs):\n",
        "        logs = {}\n",
        "        print('Epoch{}/{}'.format(epoch, epochs-1))\n",
        "        print('-' * 15)\n",
        "  \n",
        "        #Each epoch has a training and validation phase        \n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "              \n",
        "            else:\n",
        "                model.eval()\n",
        "                \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            for index, (inputs, labels) in enumerate (dataloaders[phase]):\n",
        "                inputs,labels = inputs.to(device), labels.to(device)\n",
        "                labels = labels.view(-1) # flatten\n",
        "                labels = labels.long()\n",
        "                prediction = model(inputs) \n",
        "                prediction = prediction.view(labels.size(0), -1)  #flatten\n",
        "                loss = criterion(prediction, labels) #calculate the loss between predicted and ground truth\n",
        "                optimiser.zero_grad() # zero the paratmeter gradients\n",
        "                  \n",
        "                if phase == 'train':\n",
        "                    if verbose: print('Epoch:', epoch, '\\tBatch:', index, '\\tLoss', loss.item())\n",
        "                    loss.backward()  \n",
        "                    optimiser.step() # backward + optimize only if in training phase\n",
        "\n",
        "                _, pred = torch.max(prediction, dim= 1)                  \n",
        "                running_loss += loss.detach() * inputs.size(0) \n",
        "                running_corrects += torch.sum(pred == labels.data)\n",
        "\n",
        "             # calculate average losses fo the entire epoch\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "            prefix = ''\n",
        "            if phase == 'validation':\n",
        "                prefix = 'val_'\n",
        "                \n",
        "            logs[prefix + ' loss'] = epoch_loss\n",
        "            logs[prefix + 'accuracy'] = epoch_acc\n",
        "                                    \n",
        "            #Deep copy the model\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "              best_acc = epoch_acc\n",
        "              best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        Liveloss.update(logs)\n",
        "        Liveloss.send()\n",
        "\n",
        "    time_elapse = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapse // 60, time_elapse % 60))\n",
        "    print('Best Val Acc: {}'.format(best_acc)) \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBbBD8gj7FnB",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXDFEpN6o9tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = train_model(cnn, criterion, optimiser, epochs) # 8 signals normalized data, "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl6yw3m-ycup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def measure_performance(predictions, labels):\n",
        "    \"\"\"\n",
        "    I think there's scikit learn functions for this\n",
        "    but found out after writing the function\n",
        "    \"\"\"\n",
        "    # go logical for ease\n",
        "    predictions = predictions.astype(bool)\n",
        "    labels = labels.astype(bool)\n",
        "    # true positives\n",
        "    tp = np.logical_and(predictions, labels).sum()\n",
        "    # true negatives\n",
        "    tn = np.logical_and(~predictions, ~labels).sum()\n",
        "    # false positives\n",
        "    fp = np.logical_and(predictions, ~labels).sum()\n",
        "    # false negatives\n",
        "    fn = np.logical_and(~predictions, labels).sum()\n",
        "    # accuracy\n",
        "    accuracy = (tp + tn) / len(predictions)\n",
        "    print(f\"accuracy = {accuracy}\")\n",
        "    # precision\n",
        "    precision = tp / (tp + fp)\n",
        "    print(f\"precision = {precision}\")\n",
        "    # recall\n",
        "    recall = tp / (tp + fn)\n",
        "    print(f\"recall = {recall}\")\n",
        "    # F1\n",
        "    f1 = 2*tp / (2*tp + fp + fn)\n",
        "    print(f\"F1 score = {f1}\")\n",
        "    return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKDAzZ8XzHqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "labels = []\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labs in val_loader:\n",
        "        images = images.to(device)\n",
        "        preds = cnn(images)\n",
        "        preds = torch.argmax(preds, axis=1)\n",
        "        predictions.append(preds)\n",
        "        labels.append(labs)\n",
        "        \n",
        "#concatenate accumulators into np arrays for ease of use\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "labels = np.concatenate(labels, axis=0).squeeze()\n",
        "print(classification_report(labels, predictions))\n",
        "\n",
        "# measure performance\n",
        "print(\"\\nPerformance on validation data\")\n",
        "measure_performance(predictions, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40ECQi8M0Iea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(labels, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njQoGk8W7EL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(model, dataloader):\n",
        "    num_correct = 0\n",
        "    num_examples = len(dataloader.dataset)\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs,labels = inputs.to(device),labels.to(device)\n",
        "        predictions = model(inputs)\n",
        "        predictions = torch.argmax(predictions, axis=1)\n",
        "        labels = labels.squeeze()\n",
        "        num_correct += int(sum(predictions == labels))\n",
        "        percent_correct = num_correct / num_examples * 100\n",
        "    return percent_correct\n",
        "\n",
        "\n",
        "print('Train Accuracy:', calc_accuracy (cnn, train_loader))\n",
        "print('Validation Accuracy:', calc_accuracy(cnn, val_loader))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}