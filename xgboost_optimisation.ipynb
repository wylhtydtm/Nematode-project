{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost_optimisation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Hn8Bbf7-YRSrd50PpZwAkzt7_FwlaK0t",
      "authorship_tag": "ABX9TyMQnOjrXeqotIQK1Bb31j8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wylhtydtm/Nematode-project/blob/master/xgboost_optimisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG8JloHXxGGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.model_selection._split import _BaseKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkG9gkc6xHbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/My Drive/xgboost_dataset_balanced_2/train_X_data_forxgboost.csv',index_col=None)\n",
        "test_data= pd.read_csv('/content/drive/My Drive/xgboost_dataset_balanced_2/test_X_data_forxgboost.csv',index_col=None)\n",
        "train_label= pd.read_csv('/content/drive/My Drive/xgboost_dataset_balanced_2/train_y__labelforxgboost.csv',index_col=None)\n",
        "test_label= pd.read_csv('/content/drive/My Drive/xgboost_dataset_balanced_2/test_y__labelforxgboost.csv',index_col=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awe6fUwWxs1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_groups= train_label['drug_type']\n",
        "train_y=train_label['MOA_group']\n",
        "train_X= train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09kuMMQLtAu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ee863bf-b750-4b3d-f47f-d60123ddd63a"
      },
      "source": [
        "train_data.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2449, 251)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXl9inMpXMzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StratifiedGroupKFold(_BaseKFold):\n",
        "    \"\"\"\n",
        "    Makes stratified folds according to the class labels y, but each group\n",
        "    defined in groups, is assigned in one fold (all the points of the group\n",
        "                                                are assigned to the same fold)\n",
        "    \"\"\"\n",
        "    def __init__(self, n_splits=5, random_seed=None):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "        self.seed = random_seed\n",
        "\n",
        "    def split(self, X, y, groups, seed=None):\n",
        "        if seed is None:\n",
        "            seed = self.seed\n",
        "        group_counts = pd.DataFrame(\n",
        "            {'y':y, 'groups':groups}).groupby(by='y').agg({\"groups\": \"nunique\"})\n",
        "        if np.any(group_counts.values<self.n_splits):\n",
        "            raise ValueError('Some of the classes have less groups than '+\n",
        "                             'the number of splits.')\n",
        "\n",
        "        y = LabelEncoder().fit_transform(y)\n",
        "        labels_num = np.max(y) + 1\n",
        "        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
        "        y_distr = Counter()\n",
        "        for label, g in zip(y, groups):\n",
        "            y_counts_per_group[g][label] += 1\n",
        "            y_distr[label] += 1\n",
        "\n",
        "        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
        "        groups_per_fold = defaultdict(set)\n",
        "\n",
        "        def eval_y_counts_per_fold(y_counts, fold):\n",
        "            y_counts_per_fold[fold] += y_counts\n",
        "            std_per_label = []\n",
        "            for label in range(labels_num):\n",
        "                label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(self.n_splits)])\n",
        "                std_per_label.append(label_std)\n",
        "            y_counts_per_fold[fold] -= y_counts\n",
        "            return np.mean(std_per_label)\n",
        "\n",
        "        groups_and_y_counts = list(y_counts_per_group.items())\n",
        "        random.Random(seed).shuffle(groups_and_y_counts)\n",
        "\n",
        "        for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
        "            best_fold = None\n",
        "            min_eval = None\n",
        "            for i in range(self.n_splits):\n",
        "                fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
        "                if min_eval is None or fold_eval < min_eval:\n",
        "                    min_eval = fold_eval\n",
        "                    best_fold = i\n",
        "            y_counts_per_fold[best_fold] += y_counts\n",
        "            groups_per_fold[best_fold].add(g)\n",
        "\n",
        "        all_groups = set(groups)\n",
        "        for i in range(self.n_splits):\n",
        "            train_groups = all_groups - groups_per_fold[i]\n",
        "            test_groups = groups_per_fold[i]\n",
        "\n",
        "            train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
        "            test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
        "\n",
        "            yield train_indices, test_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXhfboSPxepR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_groups= train_label['drug_type']\n",
        "train_y=train_label['MOA_group']\n",
        "train_X= train_data\n",
        "k=4\n",
        "\n",
        "test_groups= test_label['drug_type']\n",
        "test_y= test_label['MOA_group']\n",
        "test_X=test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz8VwZjCxYNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "19b0e06c-cd07-469f-cd8d-acea12fa63a1"
      },
      "source": [
        "print(train_X.shape)\n",
        "print(test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2449, 251)\n",
            "(723, 251)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU7iwFXIJHRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_8GErHKKGU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_majority_vote(\n",
        "        y_real, group,\n",
        "        y_pred=None, probas=None, labels=None,\n",
        "        vote_type='counts',\n",
        "        scorer=None\n",
        "        ):\n",
        "\n",
        "    if scorer is None:\n",
        "        score_func = accuracy_score\n",
        "    else:\n",
        "        score_func = scorer\n",
        "\n",
        "    y_real = np.asarray(y_real)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    group = np.asarray(group)\n",
        "\n",
        "    ugroups = np.unique(group)\n",
        "\n",
        "    assert np.all([np.unique(y_real[group==g]).shape[0]==1 for g in ugroups]), \\\n",
        "        'The real class labels are not unique per group.'\n",
        "\n",
        "    y_group = [np.unique(y_real[group==g])[0] for g in ugroups]\n",
        "    y_maj = get_majority_vote(\n",
        "        group, y_pred=y_pred, probas=probas, labels=labels, vote_type=vote_type)\n",
        "    y_maj = y_maj[ugroups]\n",
        "\n",
        "    return score_func(y_group, y_maj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjW70mEFdYAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_majority_vote(\n",
        "        group, y_pred=None, probas=None, labels=None, vote_type='counts'):\n",
        "    \"\"\"\n",
        "    Get the majority vote predictions per group.\n",
        "    param:\n",
        "        groups: an array defining the groups of data points (array size n_samples)\n",
        "        y_pred: the predicted class labels for each data point (array size n_samples)\n",
        "        probas: the probabilities for each class for each data point (array shape=(n_samples, n_classes) )\n",
        "        labels: the class labels that match each column of the probas array\n",
        "        vote_type: the rule the the majoroty vote is based on ['counts', 'probas']\n",
        "    \"\"\"\n",
        "\n",
        "    if probas is not None and labels is None:\n",
        "        raise ValueError('Must provide class labels corresponding to the '+\n",
        "                         'columns of the probas.')\n",
        "\n",
        "    if vote_type == 'counts' and y_pred is None:\n",
        "        if probas is None:\n",
        "            raise ValueError('Must provide either y_pred or probas to use the counts sum rule.')\n",
        "        else:\n",
        "            y_pred = [labels[maxind] for maxind in np.argmax(probas, axis=1)]\n",
        "            y_pred = np.array(y_pred)\n",
        "\n",
        "    if vote_type == 'counts' and labels is not None:\n",
        "        assert all([pred in labels for pred in y_pred]), \\\n",
        "            'The predictions in y_pred do not match the labels provided.'\n",
        "\n",
        "    if vote_type == 'counts':\n",
        "        y_maj = {}\n",
        "        for grp in np.unique(group):\n",
        "            c = Counter(y_pred[group==grp])\n",
        "\n",
        "            #value,count = c.most_common()[0]\n",
        "            counts=np.array([votes for clss,votes in c.most_common()])\n",
        "\n",
        "            if (sum(counts==counts[0])==1) or (probas is None):\n",
        "                value,count = c.most_common()[0]\n",
        "                y_maj[grp] = value\n",
        "            else:   # if more than one labels have the same number of votes and we have proba info\n",
        "                assert len(labels)==probas.shape[1]\n",
        "                values = np.array([clss for clss,votes in c.most_common()])\n",
        "                equal_classes = values[counts==counts[0]]\n",
        "                probas_of_equal_classes = []\n",
        "                for iclass in equal_classes:\n",
        "                    probas_of_equal_classes.append(\n",
        "                        np.mean(probas[group==grp, labels==iclass]))\n",
        "                most_likely_class = equal_classes[np.argmax(probas_of_equal_classes)]\n",
        "                y_maj[grp] = most_likely_class\n",
        "        y_maj = pd.Series(y_maj)\n",
        "    elif vote_type == 'probas':\n",
        "        labels = np.array(labels).reshape(-1)\n",
        "        assert labels.shape[0]==probas.shape[1]\n",
        "        group_probas = pd.DataFrame(probas).groupby(by=group).sum()\n",
        "        y_maj = pd.Series({grp:labels[np.argmax(group_probas.loc[grp,:].values)]\n",
        "                           for grp in np.unique(group)})\n",
        "\n",
        "    return y_maj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Y9Jq2fzTSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splitter=StratifiedGroupKFold(n_splits=k,random_seed=111)\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "accuracy_list=[]\n",
        "score_func_list=[]\n",
        "\n",
        "param_test0 = {\n",
        " 'n_estimators':[300,500,600,700,800,1000,1200]\n",
        "}\n",
        "\n",
        "param_test1 = {\n",
        " 'max_depth':range(3,10,2),\n",
        " 'min_child_weight':range(1,6,2)\n",
        "}\n",
        "\n",
        "param_test2 = {\n",
        " 'max_depth':[3,4,5,6,7,8],\n",
        " 'min_child_weight':[2,3,4,5,6,7]\n",
        "}\n",
        "\n",
        "for para in ParameterGrid(param_test4):\n",
        "  acc_para=[]\n",
        "  acc_score_func=[]\n",
        "  for train_ind, test_ind in splitter.split(train_X,train_y,train_groups):\n",
        "    X_train= train_X.iloc[train_ind,:]\n",
        "    y_train= train_y[train_ind]\n",
        "    X_val= train_X.iloc[test_ind,:]\n",
        "    y_val=train_y[test_ind]\n",
        "    groups_val= train_groups[test_ind]\n",
        "    model= XGBClassifier(n_estimators=800,max_depth= 3, min_child_weight=2,colsample_bytree= 0.6, subsample= 0.6,\n",
        "                         reg_alpha= 1,objective= 'multi:softmax',num_class=12,nthread=4, scale_pos_weight=1, seed=27,**para)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    predictions= [round(value) for value in y_pred]\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    acc_para.append(accuracy)\n",
        "    score_func=score_majority_vote(y_val,groups_val,y_pred=y_pred)\n",
        "    acc_score_func.append(score_func)\n",
        "\n",
        "  print(\"Accuracy: %.2f%%\" %(np.mean(acc_para)*100))\n",
        "  print(\"Majority vote accuracy:.%.2f%%\" %(np.mean(acc_score_func)*100))\n",
        "\n",
        "  accuracy_list.append(np.mean(acc_para))\n",
        "  score_func_list.append(np.mean(acc_score_func))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QHTELD9yGkWB",
        "colab": {}
      },
      "source": [
        "param_test3 = {\n",
        " 'gamma':[i/10.0 for i in range(0,5)]\n",
        "}\n",
        "\n",
        "param_test4 = {\n",
        " 'subsample':[i/10.0 for i in range(6,10)],\n",
        " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
        "}\n",
        "\n",
        "param_test5 = {\n",
        " 'reg_alpha':[ 1e-2, 0.1, 1,1.2,1.5,1.8, 2]\n",
        "}\n",
        "\n",
        "param_test6 = {\n",
        " 'learning_rate':[1e-3, 1e-2, 5e-2,0.1, 0.2,0.3]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS4bGJEBI2ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_ind=np.argmax(score_func_list)\n",
        "parameters=list(ParameterGrid(param_test4))[max_ind]\n",
        "print(parameters)\n",
        "print(max_ind)\n",
        "print(list(ParameterGrid(param_test3)))\n",
        "print(score_func_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4hP-TYJ2XC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz5R6Qg2v6oM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splitter=StratifiedGroupKFold(n_splits=k,random_seed=113)\n",
        "\n",
        "accuracy_list=[]\n",
        "score_func_list=[]\n",
        "\n",
        "for train_ind, test_ind in splitter.split(train_X,train_y,train_groups):\n",
        "  X_train= train_X.iloc[train_ind,:]\n",
        "  y_train= train_y[train_ind]\n",
        "  X_val= train_X.iloc[test_ind,:]\n",
        "  y_val=train_y[test_ind]\n",
        "  groups_val= train_groups[test_ind]\n",
        "  model= XGBClassifier(n_estimators=800,max_depth= 3, min_child_weight=2,colsample_bytree= 0.6, subsample= 0.6,\n",
        "                       reg_alpha= 1,objective= 'multi:softmax',num_class=12,nthread=4, scale_pos_weight=1, seed=27)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_val)\n",
        "  predictions= [round(value) for value in y_pred]\n",
        "  accuracy = accuracy_score(y_val, predictions)\n",
        "  score_func=score_majority_vote(y_val,groups_val,y_pred=y_pred)\n",
        "  accuracy_list.append(accuracy)\n",
        "  score_func_list.append(score_func)\n",
        "    \n",
        "print(\"Accuracy: %.2f%%\" %(np.mean(accuracy_list)*100))\n",
        "print(\"Majority vote accuracy:.%.2f%%\" %(np.mean(score_func_list)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FHrg1YzYf2p",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_D5OUbsxbie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost\n",
        "model= XGBClassifier(learning_rate=0.1,n_estimators=300,max_depth= 7, min_child_weight= 3,gamma=0,reg_alpha=1,\n",
        "                       colsample_bytree= 0.6, subsample= 0.8,objective= 'multi:softmax',num_class=12,nthread=4, scale_pos_weight=1, seed=27\n",
        "\n",
        "model= XGBClassifier(learning_rate=0.1,max_depth=3, min_child_weight= 5,n_estimators=1000,gamma=0,reg_alpha=1,\n",
        "                     colsample_bytree= 0.6, subsample= 0.8,objective= 'multi:softmax',num_class=12,nthread=4, scale_pos_weight=1, seed=27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQKrGR8J4u_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import plot_importance\n",
        "plt.rcParams['figure.figsize'] = [90, 50]\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stG6_KjIO807",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_majority_vote(\n",
        "        group, y_pred=None, probas=None, labels=None, vote_type='counts'):\n",
        "    \"\"\"\n",
        "    Get the majority vote predictions per group.\n",
        "    param:\n",
        "        groups: an array defining the groups of data points (array size n_samples)\n",
        "        y_pred: the predicted class labels for each data point (array size n_samples)\n",
        "        probas: the probabilities for each class for each data point (array shape=(n_samples, n_classes) )\n",
        "        labels: the class labels that match each column of the probas array\n",
        "        vote_type: the rule the the majoroty vote is based on ['counts', 'probas']\n",
        "    \"\"\"\n",
        "\n",
        "    if probas is not None and labels is None:\n",
        "        raise ValueError('Must provide class labels corresponding to the '+\n",
        "                         'columns of the probas.')\n",
        "\n",
        "    if vote_type == 'counts' and y_pred is None:\n",
        "        if probas is None:\n",
        "            raise ValueError('Must provide either y_pred or probas to use the counts sum rule.')\n",
        "        else:\n",
        "            y_pred = [labels[maxind] for maxind in np.argmax(probas, axis=1)]\n",
        "            y_pred = np.array(y_pred)\n",
        "\n",
        "    if vote_type == 'counts' and labels is not None:\n",
        "        assert all([pred in labels for pred in y_pred]), \\\n",
        "            'The predictions in y_pred do not match the labels provided.'\n",
        "\n",
        "    if vote_type == 'counts':\n",
        "        y_maj = {}\n",
        "        for grp in np.unique(group):\n",
        "            c = Counter(y_pred[group==grp])\n",
        "\n",
        "            #value,count = c.most_common()[0]\n",
        "            counts=np.array([votes for clss,votes in c.most_common()])\n",
        "\n",
        "            if (sum(counts==counts[0])==1) or (probas is None):\n",
        "                value,count = c.most_common()[0]\n",
        "                y_maj[grp] = value\n",
        "            else:   # if more than one labels have the same number of votes and we have proba info\n",
        "                assert len(labels)==probas.shape[1]\n",
        "                values = np.array([clss for clss,votes in c.most_common()])\n",
        "                equal_classes = values[counts==counts[0]]\n",
        "                probas_of_equal_classes = []\n",
        "                for iclass in equal_classes:\n",
        "                    probas_of_equal_classes.append(\n",
        "                        np.mean(probas[group==grp, labels==iclass]))\n",
        "                most_likely_class = equal_classes[np.argmax(probas_of_equal_classes)]\n",
        "                y_maj[grp] = most_likely_class\n",
        "        y_maj = pd.Series(y_maj)\n",
        "    elif vote_type == 'probas':\n",
        "        labels = np.array(labels).reshape(-1)\n",
        "        assert labels.shape[0]==probas.shape[1]\n",
        "        group_probas = pd.DataFrame(probas).groupby(by=group).sum()\n",
        "        y_maj = pd.Series({grp:labels[np.argmax(group_probas.loc[grp,:].values)]\n",
        "                           for grp in np.unique(group)})\n",
        "\n",
        "    return y_maj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cu9gPdnc9fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_two_most_likely_majority_vote(y_pred,groups):\n",
        "    \"\"\"\n",
        "    Estimate the classification accuracy when groups of data points are classified together based on a majority vote.\n",
        "    param:\n",
        "        y_true: the true class labels of the samples (array size n_samples)\n",
        "        y_pred: the predicted class labels from the classfier (array size n_samples)\n",
        "        groups: an array defining the groups of data points (array size n_samples)\n",
        "    \"\"\"\n",
        "\n",
        "    y_maj = np.empty((y_pred.shape[0],2))\n",
        "\n",
        "    for grp in np.unique(groups):\n",
        "\n",
        "        c = Counter(y_pred[groups==grp])\n",
        "\n",
        "        if len(c.most_common())>1:\n",
        "            for rnk in [0,1]:\n",
        "                value,count = c.most_common()[rnk]\n",
        "                y_maj[groups==grp,rnk] = value\n",
        "        else:\n",
        "            value,count = c.most_common()[0]\n",
        "            y_maj[groups==grp,:] = [value,value]\n",
        "\n",
        "        # if more than one labels have the same number of votes\n",
        "        if len(c.most_common())>1 and c.most_common()[0][1]==c.most_common()[1][1]:\n",
        "            print('Warning: the samples of compound {} are classified in more than one classes with the same frequency.'.format(grp))\n",
        "\n",
        "    return y_maj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Iy3B2Y3NAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_two_most_likely_accuracy(ytest, ytest_pred_two):\n",
        "\n",
        "    check=[]\n",
        "    for i,y in enumerate(ytest):\n",
        "        if y in ytest_pred_two[i]:\n",
        "            check.append(True)\n",
        "    acc = np.sum(check)/len(check)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqt7jkodH-02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_y_group(y, group):\n",
        "\n",
        "    y_group = pd.DataFrame(y).groupby(by=group).apply(lambda x: np.unique(x))\n",
        "\n",
        "    assert all([len(x)==1 for x in y_group.values]), 'y is not unique in each group'\n",
        "\n",
        "    y_group = y_group.apply(lambda x:x[0])\n",
        "\n",
        "    return y_group"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqAvlLXyIBxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(\n",
        "        y_true, y_pred, classes=None, normalize=False, title=None, figsize=(8,8),\n",
        "        cmap=None, saveto=None\n",
        "        ):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.utils.multiclass import unique_labels\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "#    if not title:\n",
        "#        if normalize:\n",
        "#            title = 'Normalized confusion matrix'\n",
        "#        else:\n",
        "#            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.cm.Blues\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    if classes is not None:\n",
        "        classes = [classes[key] for key in unique_labels(y_true, y_pred)]\n",
        "    else:\n",
        "        classes = unique_labels(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "\n",
        "    # create an axes on the right side of ax. The width of cax will be 5%\n",
        "    # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "    ax.figure.colorbar(im, cax=cax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "\n",
        "    if saveto is not None:\n",
        "        plt.savefig(saveto)\n",
        "        plt.close()\n",
        "    return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBfxzwE2IZJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_groups= train_label['drug_type']\n",
        "train_y=train_label['MOA_group']\n",
        "train_X= train_data\n",
        "\n",
        "test_groups= test_label['drug_type']\n",
        "test_y= test_label['MOA_group']\n",
        "test_X=test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AeZyTXrFlAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUAegbUbFpG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use Dmatrix for xgboost\n",
        "dtrain=xgb.DMatrix(train_X, label=train_y)\n",
        "dtest=xgb.DMatrix(test_X, label=test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9sBKznJGcut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = {'max_depth':3,'eta':0.1,'objective':'multi:softmax','num_class':12,'reg_alpha':1, 'colsample_bytree':0.6, 'subsample': 0.8,'min_child_weight': 5,'max_depth' :3}\n",
        "epochs=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRm61Ze5F6-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=1000\n",
        "bst=xgb.train(param, dtrain,epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is1xp5IWHOUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds= bst.predict(dtest)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJHgpVKHHsJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1282fb23-6e70-4ff0-cb6c-578eb109e648"
      },
      "source": [
        "accuracy = accuracy_score(test_y, preds)\n",
        "print(\"Accuracy: %.2f%%\" %(accuracy *100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 32.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMTzUrFRj3Q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ce72d1e-98de-415c-c5be-720171757c18"
      },
      "source": [
        "model= XGBClassifier(n_estimators=800,max_depth= 3, min_child_weight=2,colsample_bytree= 0.6, subsample= 0.6,\n",
        "                       reg_alpha= 1,objective= 'multi:softmax',num_class=12,nthread=4, scale_pos_weight=1, seed=27)\n",
        "model.fit(train_X, train_y)\n",
        "y_pred = model.predict(test_X)\n",
        "predictions= [round(value) for value in y_pred]\n",
        "accuracy = accuracy_score(test_y, predictions)\n",
        "print(\"Accuracy: %.2f%%\" %(accuracy *100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 33.47%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4u3EKCr29G6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2f804bb-a9d0-499e-8dd0-355654a091d1"
      },
      "source": [
        "score_function= score_majority_vote(y_real=test_y, group=test_groups,y_pred=preds)\n",
        "\n",
        "print(\"score_function_accuracy: %.2f%%\" %(score_function *100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score_function_accuracy: 55.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgToDXJn3JaU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4df4de30-bdd4-4964-f82e-8abd1d7f36bf"
      },
      "source": [
        "vote=get_two_most_likely_majority_vote(y_pred=preds,groups=test_groups)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: the samples of compound CSCC811993 are classified in more than one classes with the same frequency.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twlu-vN83Svb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3369bab4-a72e-47c9-9a84-34b4e335533c"
      },
      "source": [
        "acc=get_two_most_likely_accuracy(ytest=test_y, ytest_pred_two=vote)\n",
        "print(\"Accuracy: %.2f%%\" %(acc *100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnZmINmOJ1Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_maj = get_majority_vote(test_groups, y_pred=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfPuO5tEKXPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true= _get_y_group(test_y, test_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTjG0IBAKgaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6166589b-2553-4958-972b-d2f87b0ddd6c"
      },
      "source": [
        "y_maj = y_maj[y_true.index]\n",
        "print(y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drug_type\n",
            "CSAA011840     3.0\n",
            "CSAA016712     3.0\n",
            "CSAA020364    11.0\n",
            "CSAA026102     2.0\n",
            "CSAA118599     9.0\n",
            "CSAA123408     0.0\n",
            "CSAA128717     4.0\n",
            "CSAA375588    11.0\n",
            "CSAA398011     6.0\n",
            "CSCC170103    10.0\n",
            "CSCC201954     7.0\n",
            "CSCC222657     8.0\n",
            "CSCC811993     6.0\n",
            "CSCC812553    10.0\n",
            "CSCD068947     8.0\n",
            "CSCD625957     1.0\n",
            "CSCD668797     5.0\n",
            "CSCD677230     5.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8-ieWLLKiol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60657185-1214-409c-cef3-d4b987c0c12f"
      },
      "source": [
        "test_acc = accuracy_score(y_true.values, y_maj.values)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czT74_f_KoWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(y_true.values, y_maj.values,\n",
        "                      title='Test accuracy = %.2f%%'% (test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}